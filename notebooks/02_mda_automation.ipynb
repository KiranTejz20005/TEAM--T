{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c637fea",
   "metadata": {},
   "source": [
    "# F1) Automated MD&A Draft from Financials (RAG + Summarization)\n",
    "\n",
    "This notebook loads tabular financial statement extracts, computes YoY/QoQ deltas and KPIs, chunks filings/statements into retrievable text snippets, builds a vector index (Chroma), and uses Gemini to generate a sectioned MD&A draft (Trends, Revenue Drivers, Risks) with citations.\n",
    "\n",
    "Prereqs:\n",
    "- Place your CSV extracts under a data directory (e.g., `../backend/data/financials/`).\n",
    "- Ensure environment has `GEMINI_API_KEY`.\n",
    "- Dependencies: pandas, numpy, chromadb, sentence-transformers, google-generativeai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ce448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Install and Imports\n",
    "\n",
    "# If running in a fresh environment, uncomment and run the following to install missing packages.\n",
    "# %pip install pandas numpy chromadb sentence-transformers google-generativeai python-dotenv\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 180)\n",
    "\n",
    "# Local pipeline utilities\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we can import the pipeline module\n",
    "root_dir = Path(__file__).resolve().parents[1]\n",
    "nb_dir = Path(__file__).resolve().parent\n",
    "if str(nb_dir) not in os.sys.path:\n",
    "    os.sys.path.insert(0, str(nb_dir))\n",
    "\n",
    "pipeline = importlib.import_module('mda_pipeline')\n",
    "print('Loaded pipeline from:', pipeline.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Configuration and File Paths\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATA_DIR = os.getenv('MDA_DATA_DIR', str((root_dir / 'backend' / 'data').resolve()))\n",
    "COMPANY = os.getenv('MDA_COMPANY', None)  # e.g., 'AAPL'\n",
    "FILE_PATTERN = os.getenv('MDA_FILE_PATTERN', '*.csv')\n",
    "\n",
    "# Model / vector settings\n",
    "EMBED_MODEL = os.getenv('MDA_EMBED_MODEL', 'all-MiniLM-L6-v2')\n",
    "PERSIST_DIR = os.getenv('MDA_PERSIST_DIR', str((root_dir / 'chromadb').resolve()))\n",
    "\n",
    "# Output path\n",
    "OUT_DIR = os.getenv('MDA_OUT_DIR', str((root_dir / 'backend' / 'data' / 'outputs').resolve()))\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_MD_PATH = os.path.join(OUT_DIR, f'mda_{COMPANY or \"company\"}.md')\n",
    "\n",
    "print('DATA_DIR    :', DATA_DIR)\n",
    "print('COMPANY     :', COMPANY)\n",
    "print('FILE_PATTERN:', FILE_PATTERN)\n",
    "print('PERSIST_DIR :', PERSIST_DIR)\n",
    "print('OUT_MD_PATH :', OUT_MD_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load Financial Statements (CSV)\n",
    "\n",
    "raw_df = pipeline.load_financials(\n",
    "    data_dir=DATA_DIR,\n",
    "    file_pattern=FILE_PATTERN,\n",
    "    company_col='company',\n",
    "    period_col='period',\n",
    "    concept_col='concept',\n",
    "    value_col='value',\n",
    ")\n",
    "print('Raw rows:', len(raw_df))\n",
    "raw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-5) Normalize Periods and Compute YoY/QoQ Deltas & KPIs\n",
    "\n",
    "kpi_df = pipeline.compute_kpis_and_deltas(raw_df, company=COMPANY)\n",
    "print('KPI rows:', len(kpi_df))\n",
    "kpi_df.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccdb4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Minimal Unit Tests for KPI Math\n",
    "\n",
    "# Create a tiny synthetic time series to validate QoQ ~10% growth\n",
    "import math\n",
    "\n",
    "_ts = pd.Series([100, 110, 121, 133.1, 146.41])  # ~10% compounded\n",
    "_qoq = _ts.pct_change().round(3)\n",
    "assert abs(_qoq.iloc[1] - 0.10) < 0.02, 'QoQ should be ~10% at step 1'\n",
    "print('Synthetic QoQ test passed:', _qoq.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9517e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-9) Chunk KPI rows into text and build vector index (Chroma)\n",
    "\n",
    "chunks = pipeline.build_text_chunks(kpi_df)\n",
    "print('Chunks:', len(chunks))\n",
    "client, collection = pipeline.build_index(chunks, persist_path=PERSIST_DIR)\n",
    "print('Collection ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-12) Configure retriever and draft sections with citations using Gemini\n",
    "\n",
    "# Sanity retrieval\n",
    "sample_query = f\"Key trends and YoY/QoQ performance for {COMPANY or 'the company'}\"\n",
    "res = pipeline.retrieve(collection, sample_query, top_k=5)\n",
    "res_keys = {k: len(v[0]) if isinstance(v, list) else type(v) for k, v in res.items()}\n",
    "print('Retrieve keys:', res_keys)\n",
    "\n",
    "# Draft full MD&A\n",
    "md_text = pipeline.draft_mdna(collection, company=COMPANY)\n",
    "print(md_text[:800])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da13463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13-14) Assemble and persist outputs\n",
    "\n",
    "# Save markdown draft\n",
    "with open(OUT_MD_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(md_text)\n",
    "print('Saved:', OUT_MD_PATH)\n",
    "\n",
    "# Optional: save a JSON sidecar with basic info\n",
    "sidecar = {\n",
    "    'company': COMPANY,\n",
    "    'out_md': OUT_MD_PATH,\n",
    "    'data_dir': DATA_DIR,\n",
    "}\n",
    "sidecar_path = OUT_MD_PATH.replace('.md', '.json')\n",
    "with open(sidecar_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(sidecar, f, indent=2)\n",
    "print('Saved:', sidecar_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
